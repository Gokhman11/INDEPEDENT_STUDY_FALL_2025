{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJjBYVXbXhS7",
        "outputId": "55fd7525-b0b0-4fa5-e86a-18da913ee893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.2.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.0)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easyocr)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easyocr)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easyocr)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easyocr)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easyocr)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easyocr)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyclipper-1.3.0.post6 python-bidi-0.6.6\n"
          ]
        }
      ],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p0aMKghe6SN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import collections\n",
        "import os\n",
        "\n",
        "# ----------------- PARAMETERS -----------------\n",
        "BASE_ROI_WIDTH = 300   # Increased base width\n",
        "BASE_ROI_HEIGHT = 200  # Increased base height\n",
        "MIN_SCALE = 0.7        # Increased minimum scale to prevent tiny ROIs\n",
        "MAX_SCALE = 2.5        # Increased maximum scale for larger text\n",
        "SCALE_STEP = 0.2       # Smaller step for finer control\n",
        "\n",
        "HORIZONTAL_STEP = 30   # Reduced for finer movement\n",
        "VERTICAL_STEP = 30     # Reduced for finer movement\n",
        "\n",
        "NUM_EPISODES = 250     # Increased episodes for better learning\n",
        "MAX_STEPS = 30         # Increased steps per episode\n",
        "GAMMA = 0.99           # Increased discount factor for longer-term rewards\n",
        "EPSILON = 1.0          # Initial exploration probability\n",
        "EPSILON_MIN = 0.05     # Slightly higher minimum exploration\n",
        "EPSILON_DECAY = 0.997  # Slower decay for more exploration\n",
        "LEARNING_RATE = 0.0005 # Reduced learning rate for stability\n",
        "BATCH_SIZE = 64        # Increased batch size\n",
        "MEMORY_SIZE = 20000    # Larger replay buffer\n",
        "\n",
        "TARGET_SIM_THRESHOLD = 0.7  # Lowered threshold for determining target text found\n",
        "EARLY_STOP_THRESHOLD = 0.8  # Early stopping threshold\n",
        "\n",
        "# ----------------- GLOBALS -----------------\n",
        "ocr_cache = {}  # Global cache for OCR results\n",
        "reader = None   # Global EasyOCR reader\n",
        "\n",
        "# ----------------- DQN MODEL -----------------\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# ----------------- EXPERIENCE REPLAY -----------------\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "# ----------------- EASYOCR SETUP -----------------\n",
        "def setup_reader(use_gpu=True):\n",
        "    print(\"Initializing EasyOCR reader...\")\n",
        "    return easyocr.Reader(['en'], gpu=use_gpu)\n",
        "\n",
        "# ----------------- UTILITY FUNCTIONS -----------------\n",
        "def get_cropped_image(image, roi):\n",
        "    x, y, w, h = roi\n",
        "    # Ensure ROI is within image boundaries\n",
        "    x = max(0, min(x, image.shape[1] - 1))\n",
        "    y = max(0, min(y, image.shape[0] - 1))\n",
        "    w = min(w, image.shape[1] - x)\n",
        "    h = min(h, image.shape[0] - y)\n",
        "    return image[y:y+h, x:x+w]\n",
        "\n",
        "def jaccard_similarity_ngrams(text1, text2, n=2):\n",
        "    if not text1 or not text2:\n",
        "        return 0.0\n",
        "\n",
        "    t1 = text1.replace(\" \", \"\").lower()\n",
        "    t2 = text2.replace(\" \", \"\").lower()\n",
        "\n",
        "    if len(t1) < n or len(t2) < n:\n",
        "        n = 1\n",
        "\n",
        "    ngrams1 = set(t1[i:i+n] for i in range(len(t1)-n+1)) if len(t1) >= n else {t1}\n",
        "    ngrams2 = set(t2[i:i+n] for i in range(len(t2)-n+1)) if len(t2) >= n else {t2}\n",
        "\n",
        "    intersection = ngrams1.intersection(ngrams2)\n",
        "    union = ngrams1.union(ngrams2)\n",
        "    return len(intersection) / len(union) if union else 0\n",
        "\n",
        "def estimate_text_size(target_text):\n",
        "    text_len = len(target_text)\n",
        "    width_estimate = max(200, min(600, text_len * 25))\n",
        "    height_estimate = max(100, min(300, width_estimate // 2))\n",
        "    print(f\"Estimated dimensions for '{target_text}': {width_estimate}x{height_estimate}\")\n",
        "    return width_estimate, height_estimate\n",
        "\n",
        "# ----------------- OCR FUNCTION WITH CACHING -----------------\n",
        "def ocr_and_text(image, roi, target_text):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "    cropped = get_cropped_image(image, roi)\n",
        "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
        "        return \"\", 0.0\n",
        "    try:\n",
        "        results = reader.readtext(cropped)\n",
        "        if results:\n",
        "            recognized_text = \" \".join([result[1] for result in results])\n",
        "            sim = jaccard_similarity_ngrams(recognized_text, target_text)\n",
        "            return recognized_text, sim\n",
        "        return \"\", 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"OCR error: {e}\")\n",
        "        return \"\", 0.0\n",
        "\n",
        "def ocr_and_text_with_cache(image, roi, target_text, cache_precision=5):\n",
        "    # Create a cache key based on rounded ROI values\n",
        "    key = tuple(round(v, cache_precision) for v in roi)\n",
        "    if key in ocr_cache:\n",
        "        return ocr_cache[key]\n",
        "    result = ocr_and_text(image, roi, target_text)\n",
        "    ocr_cache[key] = result\n",
        "    return result\n",
        "\n",
        "def show_roi(image, roi, title=\"ROI\", similarity=0.0, text=\"\"):\n",
        "    disp_img = image.copy()\n",
        "    x, y, w, h = roi\n",
        "    color = (0, int(255 * similarity), int(255 * (1-similarity)))\n",
        "    '''\n",
        "    cv2.rectangle(disp_img, (x, y), (x+w, y+h), color, 3)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cv2.cvtColor(disp_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    plt.title(f\"{title} - Similarity: {similarity:.4f}\")\n",
        "    if text:\n",
        "        plt.figtext(0.5, 0.01, f\"Text: '{text}'\", ha=\"center\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    '''\n",
        "def calculate_reward(similarity, prev_similarity, step, roi_scale):\n",
        "    reward = similarity\n",
        "    if similarity > prev_similarity:\n",
        "        reward += 0.5 * (similarity - prev_similarity)\n",
        "    step_penalty = 0.01 * (step / MAX_STEPS)\n",
        "    reward -= step_penalty\n",
        "    if similarity > 0.8:\n",
        "        reward += 2.0\n",
        "    elif similarity > 0.6:\n",
        "        reward += 0.5\n",
        "    if roi_scale < MIN_SCALE + SCALE_STEP or roi_scale > MAX_SCALE - SCALE_STEP:\n",
        "        reward -= 0.2\n",
        "    return reward\n",
        "\n",
        "# ----------------- DQN-BASED TRAINING WITH ADAPTIVE ROI -----------------\n",
        "def train_dqn_agent(image, target_text, model_save_path=\"dqn_adaptive_ocr_model.pt\", num_episodes=NUM_EPISODES):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training on: {device}\")\n",
        "    h_img, w_img = image.shape[:2]\n",
        "    estimated_width, estimated_height = estimate_text_size(target_text)\n",
        "    print(f\"Estimated ROI dimensions for '{target_text}': {estimated_width}x{estimated_height}\")\n",
        "    base_roi_width = estimated_width\n",
        "    base_roi_height = estimated_height\n",
        "    num_actions = 12\n",
        "    input_dim = 5\n",
        "\n",
        "    policy_net = DQN(input_dim, num_actions).to(device)\n",
        "    target_net = DQN(input_dim, num_actions).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "    movement_actions = [\n",
        "        (-HORIZONTAL_STEP, 0),\n",
        "        (HORIZONTAL_STEP, 0),\n",
        "        (0, -VERTICAL_STEP),\n",
        "        (0, VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, VERTICAL_STEP)\n",
        "    ]\n",
        "    scale_actions = [\n",
        "        (-SCALE_STEP, 0),\n",
        "        (SCALE_STEP, 0),\n",
        "        (0, -SCALE_STEP),\n",
        "        (0, SCALE_STEP)\n",
        "    ]\n",
        "\n",
        "    epsilon = EPSILON\n",
        "    best_similarity = 0.0\n",
        "    best_roi = None\n",
        "    best_scale = (1.0, 1.0)\n",
        "\n",
        "    all_rewards = []\n",
        "    all_losses = []\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for episode in range(num_episodes):\n",
        "        x = random.randint(w_img//4, 3*w_img//4 - base_roi_width)\n",
        "        y = random.randint(h_img//4, 3*h_img//4 - base_roi_height)\n",
        "        width_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.4))\n",
        "        height_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.4))\n",
        "        prev_reward = 0.0\n",
        "        state = np.array([x, y, width_scale, prev_reward, 0], dtype=np.float32)\n",
        "        episode_total_reward = 0.0\n",
        "        episode_loss_sum = 0.0\n",
        "        num_loss_updates = 0\n",
        "        current_similarity = 0.0\n",
        "\n",
        "        for step in range(MAX_STEPS):\n",
        "            if random.random() < epsilon:\n",
        "                action_idx = random.randint(0, num_actions - 1)\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    state_tensor = torch.tensor(state, dtype=torch.float32).to(device).unsqueeze(0)\n",
        "                    q_values = policy_net(state_tensor)\n",
        "                    action_idx = q_values.argmax().item()\n",
        "\n",
        "            if action_idx < 8:\n",
        "                dx, dy = movement_actions[action_idx]\n",
        "                new_x = min(max(x + dx, 0), w_img - int(base_roi_width * width_scale))\n",
        "                new_y = min(max(y + dy, 0), h_img - int(base_roi_height * height_scale))\n",
        "                new_width_scale = width_scale\n",
        "                new_height_scale = height_scale\n",
        "            else:\n",
        "                new_x, new_y = x, y\n",
        "                dw_scale, dh_scale = scale_actions[action_idx - 8]\n",
        "                new_width_scale = max(MIN_SCALE, min(MAX_SCALE, width_scale + dw_scale))\n",
        "                new_height_scale = max(MIN_SCALE, min(MAX_SCALE, height_scale + dh_scale))\n",
        "                if new_x + int(base_roi_width * new_width_scale) > w_img:\n",
        "                    new_x = w_img - int(base_roi_width * new_width_scale)\n",
        "                if new_y + int(base_roi_height * new_height_scale) > h_img:\n",
        "                    new_y = h_img - int(base_roi_height * new_height_scale)\n",
        "\n",
        "            roi_width = int(base_roi_width * new_width_scale)\n",
        "            roi_height = int(base_roi_height * new_height_scale)\n",
        "            roi_width = max(100, roi_width)\n",
        "            roi_height = max(80, roi_height)\n",
        "            roi = [new_x, new_y, roi_width, roi_height]\n",
        "            recognized_text, similarity = ocr_and_text_with_cache(image, roi, target_text)\n",
        "            avg_scale = (new_width_scale + new_height_scale) / 2\n",
        "            reward = calculate_reward(similarity, current_similarity, step, avg_scale)\n",
        "            episode_total_reward += reward\n",
        "            next_state = np.array([new_x, new_y, new_width_scale, reward, step+1], dtype=np.float32)\n",
        "            done = (step == MAX_STEPS - 1) or (similarity >= EARLY_STOP_THRESHOLD)\n",
        "            memory.push(state, action_idx, reward, next_state, done)\n",
        "            state = next_state\n",
        "            x, y = new_x, new_y\n",
        "            width_scale, height_scale = new_width_scale, new_height_scale\n",
        "            current_similarity = similarity\n",
        "\n",
        "            if similarity > best_similarity:\n",
        "                best_similarity = similarity\n",
        "                best_roi = roi\n",
        "                best_scale = (width_scale, height_scale)\n",
        "                if episode % 100 == 0:\n",
        "                    show_roi(image, roi,\n",
        "                             title=f\"Episode {episode}, Step {step} - Scale: {width_scale:.2f}x{height_scale:.2f}\",\n",
        "                             similarity=similarity,\n",
        "                             text=recognized_text)\n",
        "\n",
        "            if done and similarity >= EARLY_STOP_THRESHOLD:\n",
        "                break\n",
        "\n",
        "            if len(memory) >= BATCH_SIZE:\n",
        "                batch = memory.sample(BATCH_SIZE)\n",
        "                states, actions, rewards, next_states, dones = zip(*batch)\n",
        "                states = torch.tensor(np.array(states), dtype=torch.float32).to(device)\n",
        "                actions = torch.tensor(np.array(actions), dtype=torch.int64).to(device)\n",
        "                rewards = torch.tensor(np.array(rewards), dtype=torch.float32).to(device)\n",
        "                next_states = torch.tensor(np.array(next_states), dtype=torch.float32).to(device)\n",
        "                dones = torch.tensor(np.array(dones), dtype=torch.bool).to(device)\n",
        "                current_q = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "                with torch.no_grad():\n",
        "                    max_next_q = target_net(next_states).max(1)[0]\n",
        "                    target_q = rewards + GAMMA * max_next_q * (~dones)\n",
        "                loss = criterion(current_q, target_q)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                episode_loss_sum += loss.item()\n",
        "                num_loss_updates += 1\n",
        "\n",
        "        if epsilon > EPSILON_MIN:\n",
        "            epsilon *= EPSILON_DECAY\n",
        "        if episode % 10 == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "        if episode % 200 == 0 and episode > 0:\n",
        "            torch.save({\n",
        "                'model_state_dict': policy_net.state_dict(),\n",
        "                'base_roi_width': base_roi_width,\n",
        "                'base_roi_height': base_roi_height\n",
        "            }, model_save_path)\n",
        "        if episode % 20 == 0:\n",
        "            avg_loss = episode_loss_sum / max(1, num_loss_updates)\n",
        "            avg_reward = episode_total_reward / max(1, step+1)\n",
        "            all_rewards.append(avg_reward)\n",
        "            all_losses.append(avg_loss)\n",
        "            print(f\"Episode {episode}/{num_episodes} | Reward: {episode_total_reward:.4f} | Avg Reward/Step: {avg_reward:.4f} | Loss: {avg_loss:.6f} | Epsilon: {epsilon:.4f} | Best Scale: {best_scale[0]:.2f}x{best_scale[1]:.2f} | Best Sim: {best_similarity:.4f}\")\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': policy_net.state_dict(),\n",
        "        'base_roi_width': base_roi_width,\n",
        "        'base_roi_height': base_roi_height\n",
        "    }, model_save_path)\n",
        "    print(f\"Training complete. Best similarity: {best_similarity:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(all_rewards)\n",
        "    plt.title('Average Reward per Episode')\n",
        "    plt.xlabel('Episode (x20)')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(all_losses)\n",
        "    plt.title('Loss per Episode')\n",
        "    plt.xlabel('Episode (x20)')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_stats.png')\n",
        "    plt.show()\n",
        "\n",
        "    return policy_net, best_roi, best_similarity, base_roi_width, base_roi_height\n",
        "\n",
        "# ----------------- DQN-BASED SEARCH WITH ADAPTIVE ROI -----------------\n",
        "def dqn_based_search(image, target_text, model_path=\"dqn_adaptive_ocr_model.pt\"):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    h_img, w_img = image.shape[:2]\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path)\n",
        "        model = DQN(input_dim=5, output_dim=12).to(device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        base_roi_width = checkpoint.get('base_roi_width', BASE_ROI_WIDTH)\n",
        "        base_roi_height = checkpoint.get('base_roi_height', BASE_ROI_HEIGHT)\n",
        "        print(f\"Model loaded from {model_path}\")\n",
        "        print(f\"Base ROI dimensions: {base_roi_width}x{base_roi_height}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"Using estimated dimensions and training a new model.\")\n",
        "        estimated_width, estimated_height = estimate_text_size(target_text)\n",
        "        base_roi_width = estimated_width\n",
        "        base_roi_height = estimated_height\n",
        "        model = DQN(input_dim=5, output_dim=12).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    # Optimize inference by tracing the model with TorchScript\n",
        "    example_state = torch.randn(1, 5).to(device)\n",
        "    scripted_model = torch.jit.trace(model, example_state)\n",
        "\n",
        "    movement_actions = [\n",
        "        (-HORIZONTAL_STEP, 0),\n",
        "        (HORIZONTAL_STEP, 0),\n",
        "        (0, -VERTICAL_STEP),\n",
        "        (0, VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, VERTICAL_STEP)\n",
        "    ]\n",
        "    scale_actions = [\n",
        "        (-SCALE_STEP, 0),\n",
        "        (SCALE_STEP, 0),\n",
        "        (0, -SCALE_STEP),\n",
        "        (0, SCALE_STEP)\n",
        "    ]\n",
        "\n",
        "    num_attempts = 5\n",
        "    best_roi = None\n",
        "    best_sim = 0.0\n",
        "\n",
        "    for attempt in range(num_attempts):\n",
        "        if attempt == 0:\n",
        "            x = w_img // 2 - base_roi_width // 2\n",
        "            y = h_img // 2 - base_roi_height // 2\n",
        "            width_scale = 1.0\n",
        "            height_scale = 1.0\n",
        "        else:\n",
        "            x = random.randint(w_img//4, 3*w_img//4 - base_roi_width)\n",
        "            y = random.randint(h_img//4, 3*w_img//4 - base_roi_height)\n",
        "            width_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.8))\n",
        "            height_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.8))\n",
        "\n",
        "        prev_reward = 0.0\n",
        "        state = np.array([x, y, width_scale, prev_reward, 0], dtype=np.float32)\n",
        "        attempt_sim = 0.0\n",
        "        roi_width = int(base_roi_width * width_scale)\n",
        "        roi_height = int(base_roi_height * height_scale)\n",
        "        attempt_roi = [x, y, roi_width, roi_height]\n",
        "        attempt_text = \"\"\n",
        "\n",
        "        print(f\"\\nStarting search attempt {attempt+1}/{num_attempts} with scale {width_scale:.2f}x{height_scale:.2f}...\")\n",
        "        for step in range(MAX_STEPS*2):\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32).to(device).unsqueeze(0)\n",
        "                action_idx = scripted_model(state_tensor).argmax().item()\n",
        "            if action_idx < 8:\n",
        "                dx, dy = movement_actions[action_idx]\n",
        "                x = min(max(x + dx, 0), w_img - int(base_roi_width * width_scale))\n",
        "                y = min(max(y + dy, 0), h_img - int(base_roi_height * height_scale))\n",
        "            else:\n",
        "                dw_scale, dh_scale = scale_actions[action_idx - 8]\n",
        "                width_scale = max(MIN_SCALE, min(MAX_SCALE, width_scale + dw_scale))\n",
        "                height_scale = max(MIN_SCALE, min(MAX_SCALE, height_scale + dh_scale))\n",
        "                if x + int(base_roi_width * width_scale) > w_img:\n",
        "                    x = w_img - int(base_roi_width * width_scale)\n",
        "                if y + int(base_roi_height * height_scale) > h_img:\n",
        "                    y = h_img - int(base_roi_height * height_scale)\n",
        "\n",
        "            roi_width = int(base_roi_width * width_scale)\n",
        "            roi_height = int(base_roi_height * height_scale)\n",
        "            roi_width = max(100, roi_width)\n",
        "            roi_height = max(80, roi_height)\n",
        "            roi = [x, y, roi_width, roi_height]\n",
        "            recognized_text, sim = ocr_and_text_with_cache(image, roi, target_text)\n",
        "\n",
        "            if step % 5 == 0 or sim > attempt_sim:\n",
        "                show_roi(image, roi,\n",
        "                         title=f\"Attempt {attempt+1}, Step {step} - Scale: {width_scale:.2f}x{height_scale:.2f}\",\n",
        "                         similarity=sim,\n",
        "                         text=recognized_text)\n",
        "\n",
        "            avg_scale = (width_scale + height_scale) / 2\n",
        "            reward = calculate_reward(sim, attempt_sim, step, avg_scale)\n",
        "            state = np.array([x, y, width_scale, reward, step+1], dtype=np.float32)\n",
        "            if sim > attempt_sim:\n",
        "                attempt_sim = sim\n",
        "                attempt_roi = roi\n",
        "                attempt_text = recognized_text\n",
        "            if sim >= TARGET_SIM_THRESHOLD:\n",
        "                print(f\"Target text found with similarity {sim:.4f}\")\n",
        "                break\n",
        "\n",
        "        print(f\"Attempt {attempt+1} best - Similarity: {attempt_sim:.4f}, Scale: {width_scale:.2f}x{height_scale:.2f}, Text: '{attempt_text}'\")\n",
        "        if attempt_sim > best_sim:\n",
        "            best_sim = attempt_sim\n",
        "            best_roi = attempt_roi\n",
        "\n",
        "    if best_roi:\n",
        "        recognized_text, _ = ocr_and_text_with_cache(image, best_roi, target_text)\n",
        "        show_roi(image, best_roi,\n",
        "                 title=\"Final Best Result\",\n",
        "                 similarity=best_sim,\n",
        "                 text=recognized_text)\n",
        "\n",
        "    return best_roi, best_sim\n",
        "\n",
        "# ----------------- TRAINING ON MULTIPLE EXAMPLES -----------------\n",
        "def train_on_dataset(dataset, model_save_path=\"dqn_adaptive_ocr_model.pt\"):\n",
        "    for image_path, target_text in dataset:\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image {image_path} not found, skipping.\")\n",
        "            continue\n",
        "        print(f\"\\nTraining on image: {image_path}\")\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Could not read image {image_path}, skipping.\")\n",
        "            continue\n",
        "        trained_model, best_roi, best_similarity, base_width, base_height = train_dqn_agent(\n",
        "            image, target_text, model_save_path)\n",
        "        print(f\"Finished training on {image_path}. Best similarity: {best_similarity:.4f}\")\n",
        "    torch.save(trained_model.state_dict(), model_save_path)\n",
        "    print(\"Training complete on dataset.\")\n",
        "\n",
        "# ----------------- MAIN FUNCTION -----------------\n",
        "def main():\n",
        "    mode = input(\"Train on a single image (s) or a dataset (d)? [s]: \").lower()\n",
        "    if mode == 'd':\n",
        "        dataset = [\n",
        "            (\"week_06_page_007.png\", \"It was quickly proven that Perceptron could not be trained, which led to neural network research stagnating for many years (almost a quarter of a century).\"),\n",
        "            (\"week_06_page_007.png\", \"Press Conference in 1958: the embryo of an electronic computer that [the US Navy (funding agency)] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.\"),\n",
        "            (\"week_06_page_007.png\", \"It was intended to model how the human brain processed visual data and learned to recognize objects.\"),\n",
        "            (\"week_06_page_007.png\", \"The first artificial neural network (ANN) was invented in 1958 by psychologist Frank Rosenblatt, called Perceptron.\")\n",
        "\n",
        "            ]\n",
        "        train_on_dataset(dataset)\n",
        "    else:\n",
        "        image_path = \"week_06_page_007.png\"\n",
        "        target_text = \"sign in\"\n",
        "        model_save_path = \"dqn_adaptive_ocr_model.pt\"\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Error: Image file '{image_path}' not found.\")\n",
        "            return\n",
        "        print(f\"Loading image: {image_path}\")\n",
        "        print(f\"Target text: '{target_text}'\")\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Cannot open image. Check path/filename.\")\n",
        "        if os.path.exists(model_save_path):\n",
        "            choice = input(f\"Found existing model. Train new model (t) or use existing (e)? [e]: \").lower()\n",
        "            if choice != 't':\n",
        "                final_roi, final_sim = dqn_based_search(image, target_text, model_save_path)\n",
        "                if final_roi:\n",
        "                    print(f\"Search complete. Best ROI: {final_roi}, Similarity: {final_sim:.4f}\")\n",
        "                return\n",
        "        trained_model, best_roi, best_similarity, base_width, base_height = train_dqn_agent(\n",
        "            image, target_text, model_save_path)\n",
        "        print(f\"Training complete. Best ROI during training: {best_roi}, Similarity: {best_similarity:.4f}\")\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        " #   main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Y0THaCRsNJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Make sure the following function is available in your environment.\n",
        "# It should be the same dqn_based_search function defined in your training code.\n",
        "\n",
        "def test_after_training(test_target_text='',test_image_path=''):\n",
        "    # Path to your test image and target text (modify as needed)\n",
        "    test_target_text = (\n",
        "        test_target_text\n",
        "    )\n",
        "\n",
        "    if not os.path.exists(test_image_path):\n",
        "        print(f\"Error: Test image '{test_image_path}' not found!\")\n",
        "        return\n",
        "\n",
        "    # Read the test image\n",
        "    image = cv2.imread(test_image_path)\n",
        "    if image is None:\n",
        "        print(\"Error loading test image!\")\n",
        "        return\n",
        "\n",
        "    # Run the DQN-based search using the trained model\n",
        "    best_roi, best_sim = dqn_based_search(image, test_target_text)\n",
        "\n",
        "    print(\"Test complete.\")\n",
        "    print(\"Best ROI found:\", best_roi)\n",
        "    print(\"Best similarity score:\", best_sim)\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "#    test_after_training()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec_FUgiMJamK"
      },
      "outputs": [],
      "source": [
        "def ocr_and_text(image, roi, target_text):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "    cropped = get_cropped_image(image, roi)\n",
        "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
        "        return \"\", 0.0\n",
        "    try:\n",
        "        results = reader.readtext(cropped)\n",
        "        if results:\n",
        "            recognized_text = \" \".join([result[1] for result in results])\n",
        "            sim = jaccard_similarity_ngrams(recognized_text, target_text)\n",
        "            return recognized_text, sim\n",
        "        return \"\", 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"OCR error: {e}\")\n",
        "        return \"\", 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0oS7IP9hoIK"
      },
      "outputs": [],
      "source": [
        "test_after_training('Are edges important?',test_image_path='week_04_page_006.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szni3yPCh-Ct"
      },
      "outputs": [],
      "source": [
        "test_after_training('buy it again in products')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jes2bdX6T4Vp"
      },
      "outputs": [],
      "source": [
        "taget_text='''\n",
        "It was quickly proved ee Perceptron could not be trained (reasons for this will be discussed). This leads to field of neural network research to stagnate for many years (almost quarter of a century).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IAgqvqETUng",
        "outputId": "8f1bfc53-6548-4b39-e174-cdff824f3cfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-44733471ce82>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from dqn_adaptive_ocr_model.pt\n",
            "Base ROI dimensions: 600x300\n",
            "\n",
            "Starting search attempt 1/5 with scale 1.00x1.00...\n",
            "Attempt 1 best - Similarity: 0.4262, Scale: 1.00x1.00, Text: 'existence 5 quickly proved that Percept ons for this will be discussed ork research to stagnate for entury):'\n",
            "\n",
            "Starting search attempt 2/5 with scale 1.08x1.78...\n",
            "Attempt 2 best - Similarity: 0.4351, Scale: 1.08x1.78, Text: 'press conterence In 1958: computer that [the US Navy able to walk, talk, see, write w) of its existence It was quickly proved that Pe (reasons for this will be disce network research to stagnat of a century):'\n",
            "\n",
            "Starting search attempt 3/5 with scale 1.02x1.47...\n",
            "Attempt 3 best - Similarity: 0.4672, Scale: 1.02x1.47, Text: 'able to walk, talk, see, write w) of its existence It was quickly proved that Pe (reasons for this will be discl network research to stagnate of a century):'\n",
            "\n",
            "Starting search attempt 4/5 with scale 1.29x1.73...\n",
            "Attempt 4 best - Similarity: 0.4024, Scale: 1.29x1.73, Text: 'ference in 1958: 'the embryo of an e that [the US Navy (funding agency)] lk, taik, see, write, reproduce itself a ence proved that Perceptron could no or this will be discussed): This leads esearch to stagnate for many years ry): ckly'\n",
            "\n",
            "Starting search attempt 5/5 with scale 1.12x1.26...\n",
            "Attempt 5 best - Similarity: 0.3984, Scale: 1.12x1.26, Text: 'LC proved that Perceptron could n his will be discussed). This leads arch to stagnate for many years'\n"
          ]
        }
      ],
      "source": [
        "best_roi, best_sim = dqn_based_search(img, target_text, model_path=\"dqn_adaptive_ocr_model.pt\", visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNFST4_N5WqW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ocr_and_text_qwen(image, roi, target_text):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "\n",
        "    cropped = get_cropped_image(image, roi)\n",
        "\n",
        "    # Skip OCR if ROI is too small\n",
        "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
        "        return \"\", 0.0\n",
        "\n",
        "    try:\n",
        "        #results = reader.readtext(cropped)\n",
        "        cv2.imwrite(\"cropped.png\", cropped)\n",
        "        #results = reader.readtext(\"cropped.png\")\n",
        "        # Combine all detected text\n",
        "        query = tokenizer.from_list_format([\n",
        "    {'image': 'cropped.png'},\n",
        "    {'text': 'Please extract text. Return only text without any details'},\n",
        "])\n",
        "\n",
        "        with torch.no_grad():\n",
        "               response, history = model.chat(tokenizer, query=query, history=None)\n",
        "        results=response\n",
        "        #print(results)\n",
        "        if results:\n",
        "            #recognized_text = \" \".join([result[1] for result in results])\n",
        "            recognized_text=results\n",
        "            sim = jaccard_similarity_ngrams(recognized_text, target_text)\n",
        "            print(sim)\n",
        "            return recognized_text, sim\n",
        "        return \"\", 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"OCR error: {e}\")\n",
        "        return \"\", 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOH5AzNnoA71"
      },
      "outputs": [],
      "source": [
        "test_after_training('Are edges important?',test_image_path='week_04_page_006.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM67xWSabjZZ",
        "outputId": "b3bca34f-c1e0-4972-94b8-826db7a0a6a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['fc.0.weight', 'fc.0.bias', 'fc.3.weight', 'fc.3.bias', 'fc.6.weight', 'fc.6.bias'])\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load('dqn_adaptive_ocr_model.pt')\n",
        "print(checkpoint.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqHJqC1ncvdf"
      },
      "outputs": [],
      "source": [
        "#gold\n",
        "def dqn_based_search(image, target_text, model_path=\"dqn_adaptive_ocr_model.pt\"):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    h_img, w_img = image.shape[:2]\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path)\n",
        "        model = DQN(input_dim=5, output_dim=12).to(device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        base_roi_width = checkpoint.get('base_roi_width', BASE_ROI_WIDTH)\n",
        "        base_roi_height = checkpoint.get('base_roi_height', BASE_ROI_HEIGHT)\n",
        "        print(f\"Model loaded from {model_path}\")\n",
        "        print(f\"Base ROI dimensions: {base_roi_width}x{base_roi_height}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"Using estimated dimensions and training a new model.\")\n",
        "        estimated_width, estimated_height = estimate_text_size(target_text)\n",
        "        base_roi_width = estimated_width\n",
        "        base_roi_height = estimated_height\n",
        "        model = DQN(input_dim=5, output_dim=12).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    # Optimize inference by tracing the model with TorchScript\n",
        "    example_state = torch.randn(1, 5).to(device)\n",
        "    scripted_model = torch.jit.trace(model, example_state)\n",
        "\n",
        "    movement_actions = [\n",
        "        (-HORIZONTAL_STEP, 0),\n",
        "        (HORIZONTAL_STEP, 0),\n",
        "        (0, -VERTICAL_STEP),\n",
        "        (0, VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, VERTICAL_STEP)\n",
        "    ]\n",
        "    scale_actions = [\n",
        "        (-SCALE_STEP, 0),\n",
        "        (SCALE_STEP, 0),\n",
        "        (0, -SCALE_STEP),\n",
        "        (0, SCALE_STEP)\n",
        "    ]\n",
        "\n",
        "    num_attempts = 5\n",
        "    best_roi = None\n",
        "    best_sim = 0.0\n",
        "\n",
        "    for attempt in range(num_attempts):\n",
        "        if attempt == 0:\n",
        "            x = w_img // 2 - base_roi_width // 2\n",
        "            y = h_img // 2 - base_roi_height // 2\n",
        "            width_scale = 1.0\n",
        "            height_scale = 1.0\n",
        "        else:\n",
        "            x = random.randint(w_img//4, 3*w_img//4 - base_roi_width)\n",
        "            y = random.randint(h_img//4, 3*w_img//4 - base_roi_height)\n",
        "            width_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.8))\n",
        "            height_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.8))\n",
        "\n",
        "        prev_reward = 0.0\n",
        "        state = np.array([x, y, width_scale, prev_reward, 0], dtype=np.float32)\n",
        "        attempt_sim = 0.0\n",
        "        roi_width = int(base_roi_width * width_scale)\n",
        "        roi_height = int(base_roi_height * height_scale)\n",
        "        attempt_roi = [x, y, roi_width, roi_height]\n",
        "        attempt_text = \"\"\n",
        "\n",
        "        print(f\"\\nStarting search attempt {attempt+1}/{num_attempts} with scale {width_scale:.2f}x{height_scale:.2f}...\")\n",
        "        for step in range(MAX_STEPS*2):\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32).to(device).unsqueeze(0)\n",
        "                action_idx = scripted_model(state_tensor).argmax().item()\n",
        "            if action_idx < 8:\n",
        "                dx, dy = movement_actions[action_idx]\n",
        "                x = min(max(x + dx, 0), w_img - int(base_roi_width * width_scale))\n",
        "                y = min(max(y + dy, 0), h_img - int(base_roi_height * height_scale))\n",
        "            else:\n",
        "                dw_scale, dh_scale = scale_actions[action_idx - 8]\n",
        "                width_scale = max(MIN_SCALE, min(MAX_SCALE, width_scale + dw_scale))\n",
        "                height_scale = max(MIN_SCALE, min(MAX_SCALE, height_scale + dh_scale))\n",
        "                if x + int(base_roi_width * width_scale) > w_img:\n",
        "                    x = w_img - int(base_roi_width * width_scale)\n",
        "                if y + int(base_roi_height * height_scale) > h_img:\n",
        "                    y = h_img - int(base_roi_height * height_scale)\n",
        "\n",
        "            roi_width = int(base_roi_width * width_scale)\n",
        "            roi_height = int(base_roi_height * height_scale)\n",
        "            roi_width = max(100, roi_width)\n",
        "            roi_height = max(80, roi_height)\n",
        "            roi = [x, y, roi_width, roi_height]\n",
        "            recognized_text, sim = ocr_and_text_with_cache(image, roi, target_text)\n",
        "\n",
        "            if step % 5 == 0 or sim > attempt_sim:\n",
        "                show_roi(image, roi,\n",
        "                         title=f\"Attempt {attempt+1}, Step {step} - Scale: {width_scale:.2f}x{height_scale:.2f}\",\n",
        "                         similarity=sim,\n",
        "                         text=recognized_text)\n",
        "\n",
        "            avg_scale = (width_scale + height_scale) / 2\n",
        "            reward = calculate_reward(sim, attempt_sim, step, avg_scale)\n",
        "            state = np.array([x, y, width_scale, reward, step+1], dtype=np.float32)\n",
        "            if sim > attempt_sim:\n",
        "                attempt_sim = sim\n",
        "                attempt_roi = roi\n",
        "                attempt_text = recognized_text\n",
        "            if sim >= TARGET_SIM_THRESHOLD:\n",
        "                print(f\"Target text found with similarity {sim:.4f}\")\n",
        "                break\n",
        "\n",
        "        print(f\"Attempt {attempt+1} best - Similarity: {attempt_sim:.4f}, Scale: {width_scale:.2f}x{height_scale:.2f}, Text: '{attempt_text}'\")\n",
        "        if attempt_sim > best_sim:\n",
        "            best_sim = attempt_sim\n",
        "            best_roi = attempt_roi\n",
        "\n",
        "    if best_roi:\n",
        "        recognized_text, _ = ocr_and_text_with_cache(image, best_roi, target_text)\n",
        "        show_roi(image, best_roi,\n",
        "                 title=\"Final Best Result\",\n",
        "                 similarity=best_sim,\n",
        "                 text=recognized_text)\n",
        "\n",
        "    return best_roi, best_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0niNaEkomGP"
      },
      "outputs": [],
      "source": [
        "test_after_training('P(class|Object)*P(Object)=P(class)',test_image_path='week_11_page_021.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affuiuEeq2mT",
        "outputId": "052698c0-8265-45b0-b3ef-11ebc11d1a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Test image '' not found!\n"
          ]
        }
      ],
      "source": [
        "test_after_training('P(class|Object)*P(Object)=P(class)',test_image_path='week_11_page_021.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gcCHYo0pcGj"
      },
      "outputs": [],
      "source": [
        "test_after_training('The reason of using ASPP is that it is discovered as the sampling rate becomes larger, the number of valid filter weights becomes smaller',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33fatU_Pu_Gy"
      },
      "outputs": [],
      "source": [
        "test_after_training('The reason of using ASPP is that it is discovered as the sampling rate becomes larger, the number of valid filter weights becomes smaller',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL6HfaucwlIl"
      },
      "outputs": [],
      "source": [
        "test_after_training('The reason of using ASPP is that it is discovered as the sampling rate becomes larger, the number of valid filter weights becomes smaller',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xnNLSsC0puV"
      },
      "outputs": [],
      "source": [
        "test_after_training('The reason of using ASPP is that it is discovered as the sampling rate becomes larger, the number of valid filter weights becomes smaller',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2J1ECT_4BtZ"
      },
      "outputs": [],
      "source": [
        "test_after_training('As objects of the same class can have different scales in the image, ASPP helps to account for different object scales which can improve the accuracy.',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtgZKcFn4t2-"
      },
      "outputs": [],
      "source": [
        "test_after_training('As objects of the same class can have different scales in the image, ASPP helps to account for different object scales which can improve the accuracy.',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MLqa50y6_yr"
      },
      "outputs": [],
      "source": [
        "test_after_training('Atrous Spatial Pyramid',test_image_path='week_15_page_016.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPb4cViO9WZh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWKt8DEL0oJB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEupFFshu6zL"
      },
      "outputs": [],
      "source": [
        "def dqn_based_search(image, target_text, model_path=\"dqn_adaptive_ocr_model.pt\"):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    h_img, w_img = image.shape[:2]\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path)\n",
        "        model = DQN(input_dim=5, output_dim=12).to(device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        base_roi_width = checkpoint.get('base_roi_width', BASE_ROI_WIDTH)\n",
        "        base_roi_height = checkpoint.get('base_roi_height', BASE_ROI_HEIGHT)\n",
        "        print(f\"Model loaded from {model_path}\")\n",
        "        print(f\"Base ROI dimensions: {base_roi_width}x{base_roi_height}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"Using estimated dimensions and training a new model.\")\n",
        "        estimated_width, estimated_height = estimate_text_size(target_text)\n",
        "        base_roi_width = estimated_width\n",
        "        base_roi_height = estimated_height\n",
        "        model = DQN(input_dim=5, output_dim=12).to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Optimize inference by tracing the model with TorchScript\n",
        "    example_state = torch.randn(1, 5).to(device)\n",
        "    scripted_model = torch.jit.trace(model, example_state)\n",
        "\n",
        "    movement_actions = [\n",
        "        (-HORIZONTAL_STEP, 0),\n",
        "        (HORIZONTAL_STEP, 0),\n",
        "        (0, -VERTICAL_STEP),\n",
        "        (0, VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, -VERTICAL_STEP),\n",
        "        (-HORIZONTAL_STEP, VERTICAL_STEP),\n",
        "        (HORIZONTAL_STEP, VERTICAL_STEP)\n",
        "    ]\n",
        "    scale_actions = [\n",
        "        (-SCALE_STEP, 0),\n",
        "        (SCALE_STEP, 0),\n",
        "        (0, -SCALE_STEP),\n",
        "        (0, SCALE_STEP)\n",
        "    ]\n",
        "\n",
        "    # Start the search with a number of attempts\n",
        "    num_attempts = 5\n",
        "    best_roi = None\n",
        "    best_sim = 0.0\n",
        "    best_text = \"\"\n",
        "\n",
        "    for attempt in range(num_attempts):\n",
        "        if attempt == 0:\n",
        "            # Center the ROI initially\n",
        "            x = w_img // 2 - base_roi_width // 2\n",
        "            y = h_img // 2 - base_roi_height // 2\n",
        "            width_scale = 1.0\n",
        "            height_scale = 1.0\n",
        "        else:\n",
        "            # Random starting position for further attempts\n",
        "            x = random.randint(w_img//4, 3*w_img//4 - base_roi_width)\n",
        "            y = random.randint(h_img//4, 3*w_img//4 - base_roi_height)\n",
        "            width_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.8))\n",
        "            height_scale = max(MIN_SCALE, min(MAX_SCALE, 1.0 + random.random() * 0.8))\n",
        "\n",
        "        prev_reward = 0.0\n",
        "        state = np.array([x, y, width_scale, prev_reward, 0], dtype=np.float32)\n",
        "        attempt_sim = 0.0\n",
        "        roi_width = int(base_roi_width * width_scale)\n",
        "        roi_height = int(base_roi_height * height_scale)\n",
        "        attempt_roi = [x, y, roi_width, roi_height]\n",
        "        attempt_text = \"\"\n",
        "\n",
        "        print(f\"\\nStarting search attempt {attempt+1}/{num_attempts} with scale {width_scale:.2f}x{height_scale:.2f}...\")\n",
        "        for step in range(MAX_STEPS*2):\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32).to(device).unsqueeze(0)\n",
        "                action_idx = scripted_model(state_tensor).argmax().item()\n",
        "\n",
        "            # Take the action based on the model's output\n",
        "            if action_idx < 8:\n",
        "                dx, dy = movement_actions[action_idx]\n",
        "                x = min(max(x + dx, 0), w_img - int(base_roi_width * width_scale))\n",
        "                y = min(max(y + dy, 0), h_img - int(base_roi_height * height_scale))\n",
        "            else:\n",
        "                dw_scale, dh_scale = scale_actions[action_idx - 8]\n",
        "                width_scale = max(MIN_SCALE, min(MAX_SCALE, width_scale + dw_scale))\n",
        "                height_scale = max(MIN_SCALE, min(MAX_SCALE, height_scale + dh_scale))\n",
        "                if x + int(base_roi_width * width_scale) > w_img:\n",
        "                    x = w_img - int(base_roi_width * width_scale)\n",
        "                if y + int(base_roi_height * height_scale) > h_img:\n",
        "                    y = h_img - int(base_roi_height * height_scale)\n",
        "\n",
        "            # Create new ROI and check Jaccard similarity\n",
        "            roi_width = int(base_roi_width * width_scale)\n",
        "            roi_height = int(base_roi_height * height_scale)\n",
        "            roi_width = max(100, roi_width)\n",
        "            roi_height = max(80, roi_height)\n",
        "            roi = [x, y, roi_width, roi_height]\n",
        "            recognized_text, sim = ocr_and_text_with_cache(image, roi, target_text)\n",
        "\n",
        "            # Show ROI at regular intervals\n",
        "            if step % 5 == 0 or sim > attempt_sim:\n",
        "                show_roi(image, roi,\n",
        "                         title=f\"Attempt {attempt+1}, Step {step} - Scale: {width_scale:.2f}x{height_scale:.2f}\",\n",
        "                         similarity=sim,\n",
        "                         text=recognized_text)\n",
        "\n",
        "            avg_scale = (width_scale + height_scale) / 2\n",
        "            reward = calculate_reward(sim, attempt_sim, step, avg_scale)\n",
        "            state = np.array([x, y, width_scale, reward, step+1], dtype=np.float32)\n",
        "\n",
        "            if sim > attempt_sim:\n",
        "                attempt_sim = sim\n",
        "                attempt_roi = roi\n",
        "                attempt_text = recognized_text\n",
        "\n",
        "            # If target similarity is reached, break early\n",
        "            if sim >= TARGET_SIM_THRESHOLD:\n",
        "                print(f\"Target text found with similarity {sim:.4f}\")\n",
        "                break\n",
        "\n",
        "        print(f\"Attempt {attempt+1} best - Similarity: {attempt_sim:.4f}, Scale: {width_scale:.2f}x{height_scale:.2f}, Text: '{attempt_text}'\")\n",
        "\n",
        "        if attempt_sim > best_sim:\n",
        "            best_sim = attempt_sim\n",
        "            best_roi = attempt_roi\n",
        "            best_text = attempt_text\n",
        "\n",
        "    # Now refine the best ROI found\n",
        "    if best_roi:\n",
        "        print(\"\\nRefining the best ROI...\")\n",
        "        refined_roi = refine_roi_adjustment(image, target_text, best_roi)\n",
        "        recognized_text, final_sim = ocr_and_text_with_cache(image, refined_roi, target_text)\n",
        "        show_roi(image, refined_roi,\n",
        "                 title=\"Refined Best Result\",\n",
        "                 similarity=final_sim,\n",
        "                 text=recognized_text)\n",
        "\n",
        "        return refined_roi, final_sim\n",
        "\n",
        "def refine_roi_adjustment(image, target_text, best_roi, max_adjustments=5, scale_step=SCALE_STEP, step_size=HORIZONTAL_STEP):\n",
        "    x, y, w, h = best_roi\n",
        "    best_similarity = 0.0\n",
        "    refined_roi = best_roi  # Start with the best found ROI\n",
        "    last_sim = 0.0\n",
        "    direction = None  # Track whether we are moving left or right\n",
        "    max_width = image.shape[1]\n",
        "\n",
        "    print(\"Refining ROI by adjusting left/right direction...\")\n",
        "    for _ in range(max_adjustments):\n",
        "        # Try moving left and right by step_size\n",
        "        left_roi = [max(0, x - step_size), y, w, h]  # Move left\n",
        "        right_roi = [min(max_width - w, x + step_size), y, w, h]  # Move right\n",
        "\n",
        "        # Check similarity for both adjustments\n",
        "        left_text, left_sim = ocr_and_text_with_cache(image, left_roi, target_text)\n",
        "        right_text, right_sim = ocr_and_text_with_cache(image, right_roi, target_text)\n",
        "\n",
        "        # If similarity increases, continue in the best direction\n",
        "        if left_sim > best_similarity:\n",
        "            best_similarity = left_sim\n",
        "            refined_roi = left_roi\n",
        "            direction = \"left\"\n",
        "        elif right_sim > best_similarity:\n",
        "            best_similarity = right_sim\n",
        "            refined_roi = right_roi\n",
        "            direction = \"right\"\n",
        "\n",
        "        # Check if the similarity is not improving\n",
        "        if last_sim == best_similarity:\n",
        "            break\n",
        "\n",
        "        last_sim = best_similarity\n",
        "\n",
        "    # Adjust the ROI size to capture the entire next line\n",
        "    x, y, w, h = refined_roi\n",
        "    expanded_roi = [max(0, x - 20), y, min(max_width - x + 20, w + 40), h + 40]  # Expand width and height\n",
        "\n",
        "    print(f\"Refined ROI after adjusting: {expanded_roi}\")\n",
        "\n",
        "    return expanded_roi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtxDAHcJ4rNc"
      },
      "outputs": [],
      "source": [
        "def ocr_and_text_llm(image, roi, target_text):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        reader = setup_reader()\n",
        "\n",
        "    cropped = get_cropped_image(image, roi)\n",
        "\n",
        "    # Skip OCR if ROI is too small\n",
        "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
        "        return \"\", 0.0\n",
        "\n",
        "    try:\n",
        "        #results = reader.readtext(cropped)\n",
        "        cv2.imwrite(\"cropped.png\", cropped)\n",
        "        #results = reader.readtext(\"cropped.png\")\n",
        "        # Combine all detected text\n",
        "        query = tokenizer.from_list_format([\n",
        "    {'image': 'cropped.png'},\n",
        "    {'text': 'Please extract text. Return only text without any details'},\n",
        "])\n",
        "\n",
        "        with torch.no_grad():\n",
        "               response, history = model.chat(tokenizer, query=query, history=None)\n",
        "        results=response\n",
        "        #print(results)\n",
        "        if results:\n",
        "            #recognized_text = \" \".join([result[1] for result in results])\n",
        "            recognized_text=results\n",
        "            sim = jaccard_similarity_ngrams(recognized_text, target_text)\n",
        "            print(sim)\n",
        "            return recognized_text, sim\n",
        "        return \"\", 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"OCR error: {e}\")\n",
        "        return \"\", 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1hhZKHA6uCt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------- OCR FUNCTION WITH CACHING -----------------\n",
        "def ocr_and_text(image, roi, target_text):\n",
        "    global reader\n",
        "    if reader is None:\n",
        "        setup_reader()\n",
        "    cropped = get_cropped_image(image, roi)\n",
        "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
        "        return \"\", 0.0\n",
        "    try:\n",
        "        results = reader.readtext(cropped)\n",
        "        if results:\n",
        "            recognized_text = \" \".join([result[1] for result in results])\n",
        "            print(f\"Recognized text: '{recognized_text}'\")\n",
        "            sim = jaccard_similarity_ngrams(recognized_text, target_text)\n",
        "            return recognized_text, sim\n",
        "        return \"\", 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"OCR error: {e}\")\n",
        "        return \"\", 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "375RaGaX9Xq_"
      },
      "outputs": [],
      "source": [
        "test_after_training('Principal Components Analysis (PCA): Seeks a projection that preserves as much information in the data as possible.',test_image_path='week_05_page_011.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKLZD9CL-xiI"
      },
      "outputs": [],
      "source": [
        "test_after_training('Principal Components Analysis (PCA): Seeks a projection that preserves as much information in the data as possible.',test_image_path='week_05_page_011.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYzoaJmP_ceg"
      },
      "outputs": [],
      "source": [
        "test_after_training('We begin with a distance matrix which contains the distances between every pair of objects in our database.',test_image_path='week_07_page_023.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb2rsriAAGa_"
      },
      "outputs": [],
      "source": [
        "test_after_training('Drawbacks',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpI3EgEKBdIg"
      },
      "outputs": [],
      "source": [
        "test_after_training('6x6',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1rdGH4DBkMj"
      },
      "outputs": [],
      "source": [
        "test_after_training('3 x 3',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pxjm878jBu7U"
      },
      "outputs": [],
      "source": [
        "test_after_training('3x3',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A8qtTjbORji",
        "outputId": "fe4092d5-4246-4e70-f218-b67ebc0991e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading model: 'model_state_dict'\n",
            "Using estimated dimensions and training a new model.\n",
            "Estimated dimensions for 'The Inception network was an important milestone in the development of CNN classifiers.': 600x300\n",
            "\n",
            "Starting search attempt 1/5 with scale 1.00x1.00...\n",
            "Attempt 1 best - Similarity: 0.5938, Scale: 1.00x1.00, Text: 'ion Network Mot ption network was an imp ment of CNN classifiers.'\n",
            "\n",
            "Starting search attempt 2/5 with scale 1.24x1.21...\n",
            "Attempt 2 best - Similarity: 0.5301, Scale: 1.24x1.21, Text: 'The Inception network W development of CNN clas It changed the idea of fin layers. Instead of choosin'\n",
            "\n",
            "Starting search attempt 3/5 with scale 1.75x1.22...\n",
            "Target text found with similarity 0.8382\n",
            "Attempt 3 best - Similarity: 0.8382, Scale: 1.75x1.22, Text: 'ception Network Motivation he Inception network was an important milest levelopment of CNN classifiers.'\n",
            "\n",
            "Starting search attempt 4/5 with scale 1.32x1.06...\n",
            "Target text found with similarity 0.7015\n",
            "Attempt 4 best - Similarity: 0.7015, Scale: 1.32x1.06, Text: 'ption Network Motiva Inception network was an importa elopment of CNN classifiers.'\n",
            "\n",
            "Starting search attempt 5/5 with scale 1.07x1.73...\n",
            "Attempt 5 best - Similarity: 0.5161, Scale: 1.07x1.73, Text: 'Inception network was an ir elopment of CNN classifiers: anged the idea of finding o rs. Instead of choosing differ ifferent layers, \"inception me'\n",
            "Test complete.\n",
            "Best ROI found: [205, 81, 1050, 367]\n",
            "Best similarity score: 0.8382352941176471\n"
          ]
        }
      ],
      "source": [
        "test_after_training('The Inception network was an important milestone in the development of CNN classifiers.',test_image_path='week_09_page_017.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_7G3V2IOYrN"
      },
      "outputs": [],
      "source": [
        "test_after_training('4x4',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FhbITcOB9NW"
      },
      "outputs": [],
      "source": [
        "test_after_training('Shrinking output Every time when image is convolved with the filter, its size shrinks. It means only few times this operation can be applied before image shrinks to the level that it losses information (problem when you build deep CNN).',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RFkta3DCT1y"
      },
      "outputs": [],
      "source": [
        "test_after_training('4 x 4',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsO9ex73Czpe"
      },
      "outputs": [],
      "source": [
        "test_after_training('6 x 6',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2DmYgO5Pp7g"
      },
      "outputs": [],
      "source": [
        "test_after_training('Edges are importantt',test_image_path='week_04_page_006.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcQdNKi2O6uY"
      },
      "outputs": [],
      "source": [
        "test_after_training('All these images are just edges, there is no color information, just edges, but still, we humans have the ability to understand information conveyed only by edges.',test_image_path='week_07_page_030.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoDbF3C_QOxz"
      },
      "outputs": [],
      "source": [
        "test_after_training('All these images are just edges, there is no color information, just edges, but still, we humans have the ability to understand information conveyed only by edges.',test_image_path='week_04_page_006.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfU2GgIcQb0G"
      },
      "outputs": [],
      "source": [
        "test_after_training('Are edges important?',test_image_path='week_04_page_006.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpGhV6QKQtqV"
      },
      "outputs": [],
      "source": [
        "test_after_training('Edges are important',test_image_path='week_04_page_006.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfxKNkm0RQ8z"
      },
      "outputs": [],
      "source": [
        "test_after_training('100 billion neuron in human brain',test_image_path='week_06_page_008.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leWH768ZB8En"
      },
      "source": [
        "Shrinking output Every time when image is convolved with the filter, its size shrinks. It means only few times this operation can be applied before image shrinks to the level that it losses information (problem when you build deep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyZHHnP-VEDM",
        "outputId": "eeae71f5-9692-43f2-f46f-50586b30b3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing EasyOCR reader...\n",
            "Error loading model: 'model_state_dict'\n",
            "Using estimated dimensions and training a new model.\n",
            "Estimated dimensions for '• It changed the idea of finding optimized filters, filter sizes in different layers. Instead of choosing different filter sizes and type of operations in different layers, \"inception module\" does all in one.': 600x300\n",
            "\n",
            "Starting search attempt 1/5 with scale 1.00x1.00...\n",
            "Attempt 1 best - Similarity: 0.5213, Scale: 1.00x1.00, Text: 'finding optimized filters, fil sing different filter sizes ar eption module\" does all in'\n",
            "\n",
            "Starting search attempt 2/5 with scale 1.11x1.48...\n",
            "Attempt 2 best - Similarity: 0.0000, Scale: 1.11x1.48, Text: ''\n",
            "\n",
            "Starting search attempt 3/5 with scale 1.21x1.53...\n",
            "Attempt 3 best - Similarity: 0.0000, Scale: 1.21x1.53, Text: ''\n",
            "\n",
            "Starting search attempt 4/5 with scale 1.33x1.59...\n",
            "Attempt 4 best - Similarity: 0.0000, Scale: 1.33x1.59, Text: ''\n",
            "\n",
            "Starting search attempt 5/5 with scale 1.69x1.57...\n",
            "Attempt 5 best - Similarity: 0.0000, Scale: 1.69x1.57, Text: ''\n",
            "Test complete.\n",
            "Best ROI found: [690, 420, 600, 300]\n",
            "Best similarity score: 0.5212765957446809\n"
          ]
        }
      ],
      "source": [
        "test_after_training('• It changed the idea of finding optimized filters, filter sizes in different layers. Instead of choosing different filter sizes and type of operations in different layers, \"inception module\" does all in one.',test_image_path='week_09_page_017.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- PARAMETERS -----------------\n",
        "RESIZE_STEP      = 20\n",
        "ROI_WIDTH_MIN    = 60\n",
        "ROI_HEIGHT_MIN   = 60\n",
        "PADDING          = 200   # white border around image\n",
        "MAX_NO_IMPROVE   = 20    # stop after 20 steps with sim < best\n",
        "MAX_NO_CHANGE    = 10    # stop after 10 steps with sim == last\n",
        "\n",
        "# ----------------- EASYOCR SETUP -----------------\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# ----------------- HELPERS -----------------\n",
        "def get_cropped_image(image, roi):\n",
        "    x, y, w, h = roi\n",
        "    x0, y0 = max(0, x), max(0, y)\n",
        "    x1     = min(x + w, image.shape[1])\n",
        "    y1     = min(y + h, image.shape[0])\n",
        "    return image[y0:y1, x0:x1]\n",
        "\n",
        "def normalized_levenshtein_ratio(a, b):\n",
        "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
        "\n",
        "def preprocess_image(img):\n",
        "    gray      = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur      = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "    sharpened = cv2.addWeighted(gray, 1.5, blur, -0.5, 0)\n",
        "    _, thresh = cv2.threshold(sharpened, 0, 255,\n",
        "                              cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return thresh\n",
        "\n",
        "def ocr_and_text(image, roi, target):\n",
        "    crop = get_cropped_image(image, roi)\n",
        "    prep = preprocess_image(crop)\n",
        "    try:\n",
        "        results = reader.readtext(prep)\n",
        "    except Exception as e:\n",
        "        print(\"OCR error:\", e)\n",
        "        return \"\", 0.0\n",
        "    if not results:\n",
        "        return \"\", 0.0\n",
        "    text = \" \".join([r[1] for r in results])\n",
        "    sim  = normalized_levenshtein_ratio(text, target)\n",
        "    return text, sim\n",
        "\n",
        "def show_roi(img, roi, title=\"ROI\"):\n",
        "    disp = img.copy()\n",
        "    x, y, w, h = roi\n",
        "    cv2.rectangle(disp, (x,y), (x+w,y+h), (0,0,255), 2)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.imshow(cv2.cvtColor(disp, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ----------------- ROI ADJUSTER -----------------\n",
        "class ROIAdjuster:\n",
        "    def __init__(self, image, roi, target, prev_sim):\n",
        "        self.image    = image\n",
        "        self.roi      = roi\n",
        "        self.target   = target\n",
        "        self.prev_sim = prev_sim\n",
        "\n",
        "    def refine_roi(self):\n",
        "        best_roi = self.roi\n",
        "        best_sim = self.prev_sim\n",
        "\n",
        "        for direction in ['left', 'right', 'up', 'down']:\n",
        "            print(f\"\\n=== Expanding {direction.upper()} ===\")\n",
        "            current_roi = best_roi\n",
        "            low_count   = 0\n",
        "            same_count  = 0\n",
        "            last_sim    = best_sim\n",
        "\n",
        "            # try up to N expansions or until boundary\n",
        "            for _ in range(200):\n",
        "                x, y, w, h = current_roi\n",
        "                if direction == 'left':\n",
        "                    x -= RESIZE_STEP; w += RESIZE_STEP\n",
        "                elif direction == 'right':\n",
        "                    w += RESIZE_STEP\n",
        "                elif direction == 'up':\n",
        "                    y -= RESIZE_STEP; h += RESIZE_STEP\n",
        "                else:  # down\n",
        "                    h += RESIZE_STEP\n",
        "\n",
        "                cand = [x, y, w, h]\n",
        "                constrained = self.constrain_roi(cand)\n",
        "\n",
        "                # stop if we hit the padded edge\n",
        "                if constrained == current_roi:\n",
        "                    print(f\"— Hit {direction} boundary, stopping\")\n",
        "                    break\n",
        "\n",
        "                current_roi = constrained\n",
        "                text, sim = ocr_and_text(self.image, current_roi, self.target)\n",
        "\n",
        "                print(f\"  → ROI: {current_roi}, Sim={sim:.4f}\")\n",
        "                print(f\"    Text snippet: {text[:60]}…\")\n",
        "\n",
        "                # update counts\n",
        "                if sim > best_sim:\n",
        "                    best_roi, best_sim = current_roi, sim\n",
        "                    low_count  = 0\n",
        "                    same_count = 0\n",
        "                    last_sim   = sim\n",
        "                    print(f\"    ✔ New best: {best_sim:.4f}\")\n",
        "                elif sim < best_sim:\n",
        "                    low_count += 1\n",
        "                    same_count = 0\n",
        "                else:  # sim == last_sim\n",
        "                    same_count += 1\n",
        "\n",
        "                # stop policies\n",
        "                if low_count > MAX_NO_IMPROVE:\n",
        "                    print(f\"— Stopping {direction}: {low_count} low-sim steps\")\n",
        "                    break\n",
        "                if same_count > MAX_NO_CHANGE:\n",
        "                    print(f\"— Stopping {direction}: {same_count} unchanged-sim steps\")\n",
        "                    break\n",
        "\n",
        "            # end for expansions\n",
        "\n",
        "        return best_roi\n",
        "\n",
        "    def constrain_roi(self, roi):\n",
        "        x, y, w, h = roi\n",
        "        img_h, img_w = self.image.shape[:2]\n",
        "        x = max(0, min(x, img_w - w))\n",
        "        y = max(0, min(y, img_h - h))\n",
        "        w = max(ROI_WIDTH_MIN, min(w, img_w - x))\n",
        "        h = max(ROI_HEIGHT_MIN, min(h, img_h - y))\n",
        "        return [x, y, w, h]\n",
        "\n",
        "# ----------------- MAIN -----------------\n",
        "orig = cv2.imread('week_09_page_017.png')\n",
        "if orig is None:\n",
        "    raise FileNotFoundError(\"Image not found.\")\n",
        "img = cv2.copyMakeBorder(orig, PADDING, PADDING, PADDING, PADDING,\n",
        "                         cv2.BORDER_CONSTANT, value=[255,255,255])\n",
        "\n",
        "target = (\n",
        "    '• It changed the idea of finding optimized filters, '\n",
        "    'filter sizes in different layers. Instead of choosing '\n",
        "    'different filter sizes and type of operations in different layers, '\n",
        "    '\"inception module\" does all in one.'\n",
        ")\n",
        "initial_roi = [690 + PADDING, 420 + PADDING, 600, 300]\n",
        "_, start_sim = ocr_and_text(img, initial_roi, target)\n",
        "print(f\"Start similarity: {start_sim:.4f}\")\n",
        "\n",
        "show_roi(img, initial_roi, \"Initial ROI\")\n",
        "\n",
        "adjuster = ROIAdjuster(img, initial_roi, target, start_sim)\n",
        "final_roi = adjuster.refine_roi()\n",
        "\n",
        "show_roi(img, final_roi, \"Refined ROI\")\n",
        "\n",
        "# map back and save\n",
        "x, y, w, h = final_roi\n",
        "orig_roi = [x - PADDING, y - PADDING, w, h]\n",
        "crop = get_cropped_image(orig, orig_roi)\n",
        "cv2.imwrite('refined_crop.png', crop)\n",
        "print(\"\\nFinal ROI on padded image:\", final_roi)\n",
        "print(\"Final ROI on original image:\", orig_roi)\n",
        "print(\"Cropped region saved as: refined_crop.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xEuBuzBuDEm_",
        "outputId": "931a6d0b-b821-4123-b6f3-7bec0787f0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start similarity: 0.5405\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Expanding LEFT ===\n",
            "  → ROI: [870, 620, 620, 300], Sim=0.5467\n",
            "    Text snippet: 1 finding optimized filters, fil osing different filter size…\n",
            "    ✔ New best: 0.5467\n",
            "  → ROI: [850, 620, 640, 300], Sim=0.5515\n",
            "    Text snippet: f finding optimized filters, fiL osing different filter size…\n",
            "    ✔ New best: 0.5515\n",
            "  → ROI: [830, 620, 660, 300], Sim=0.5592\n",
            "    Text snippet: of finding optimized filters, fil oosing different filter si…\n",
            "    ✔ New best: 0.5592\n",
            "  → ROI: [810, 620, 680, 300], Sim=0.5621\n",
            "    Text snippet: of finding optimized filters, fil hoosing different filter s…\n",
            "    ✔ New best: 0.5621\n",
            "  → ROI: [790, 620, 700, 300], Sim=0.2524\n",
            "    Text snippet: a of finding optimized filters, fil choosing different filte…\n",
            "  → ROI: [770, 620, 720, 300], Sim=0.2258\n",
            "    Text snippet: ea of finding optimized filters, fil choosing different filt…\n",
            "  → ROI: [750, 620, 740, 300], Sim=0.2461\n",
            "    Text snippet: lea of finding optimized filters, fil f choosing different f…\n",
            "  → ROI: [730, 620, 760, 300], Sim=0.2453\n",
            "    Text snippet: dea of finding optimized filters, fil of choosing different …\n",
            "  → ROI: [710, 620, 780, 300], Sim=0.2500\n",
            "    Text snippet: idea of finding optimized filters, fi= of choosing different…\n",
            "  → ROI: [690, 620, 800, 300], Sim=0.2646\n",
            "    Text snippet: 2 idea of finding optimized filters, fil J of choosing diffe…\n",
            "  → ROI: [670, 620, 820, 300], Sim=0.2699\n",
            "    Text snippet: e idea of finding optimized filters, fil d of choosing diffe…\n",
            "  → ROI: [650, 620, 840, 300], Sim=0.2796\n",
            "    Text snippet: he idea of finding optimized filters, fil ad of choosing dif…\n",
            "  → ROI: [630, 620, 860, 300], Sim=0.2779\n",
            "    Text snippet: the idea of finding optimized filters, fiL ead of choosing d…\n",
            "  → ROI: [610, 620, 880, 300], Sim=0.2806\n",
            "    Text snippet:  the idea of finding optimized filters, fil tead of choosing…\n",
            "  → ROI: [590, 620, 900, 300], Sim=0.2840\n",
            "    Text snippet: d the idea of finding optimized filters, fil stead of choosi…\n",
            "  → ROI: [570, 620, 920, 300], Sim=0.2874\n",
            "    Text snippet: ed the idea of finding optimized filters, fi= Istead of choo…\n",
            "  → ROI: [550, 620, 940, 300], Sim=0.2874\n",
            "    Text snippet: ed the idea of finding optimized filters, fil nstead of choo…\n",
            "  → ROI: [530, 620, 960, 300], Sim=0.2907\n",
            "    Text snippet: ged the idea of finding optimized filters, fil Instead of ch…\n",
            "  → ROI: [510, 620, 980, 300], Sim=0.3006\n",
            "    Text snippet: the idea of finding optimized filters, fil Instead of choosi…\n",
            "  → ROI: [490, 620, 1000, 300], Sim=0.2963\n",
            "    Text snippet: anged the idea of finding optimized filters, fiL s. Instead …\n",
            "  → ROI: [470, 620, 1020, 300], Sim=0.3051\n",
            "    Text snippet: anged the idea of finding optimized filters, fiL rs. Instead…\n",
            "  → ROI: [450, 620, 1040, 300], Sim=0.3025\n",
            "    Text snippet: hanged the idea of finding optimized filters, fil ers. Inste…\n",
            "  → ROI: [430, 620, 1060, 300], Sim=0.7263\n",
            "    Text snippet: changed the idea of finding optimized filters, fil vers Inst…\n",
            "    ✔ New best: 0.7263\n",
            "  → ROI: [410, 620, 1080, 300], Sim=0.7479\n",
            "    Text snippet: changed the idea of finding optimized filters, fiL yers. Ins…\n",
            "    ✔ New best: 0.7479\n",
            "  → ROI: [390, 620, 1100, 300], Sim=0.7582\n",
            "    Text snippet: t changed the idea of finding optimized filters, fil ayers. …\n",
            "    ✔ New best: 0.7582\n",
            "  → ROI: [370, 620, 1120, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "    ✔ New best: 0.7684\n",
            "  → ROI: [350, 620, 1140, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [330, 620, 1160, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [310, 620, 1180, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [290, 620, 1200, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [270, 620, 1220, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fiL layers…\n",
            "  → ROI: [250, 620, 1240, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [230, 620, 1260, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [210, 620, 1280, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [190, 620, 1300, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fiL layers…\n",
            "  → ROI: [170, 620, 1320, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "  → ROI: [150, 620, 1340, 300], Sim=0.7684\n",
            "    Text snippet: It changed the idea of finding optimized filters, fil layers…\n",
            "— Stopping left: 11 unchanged-sim steps\n",
            "\n",
            "=== Expanding RIGHT ===\n",
            "  → ROI: [370, 620, 1140, 300], Sim=0.7772\n",
            "    Text snippet: It changed the idea of finding optimized filters, filt layer…\n",
            "    ✔ New best: 0.7772\n",
            "  → ROI: [370, 620, 1160, 300], Sim=0.7892\n",
            "    Text snippet: It changed the idea of finding optimized filters, filte laye…\n",
            "    ✔ New best: 0.7892\n",
            "  → ROI: [370, 620, 1180, 300], Sim=0.7914\n",
            "    Text snippet: It changed the idea of finding optimized filters, filten lay…\n",
            "    ✔ New best: 0.7914\n",
            "  → ROI: [370, 620, 1200, 300], Sim=0.8021\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter lay…\n",
            "    ✔ New best: 0.8021\n",
            "  → ROI: [370, 620, 1220, 300], Sim=0.8971\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter lay…\n",
            "    ✔ New best: 0.8971\n",
            "  → ROI: [370, 620, 1240, 300], Sim=0.9034\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter si …\n",
            "    ✔ New best: 0.9034\n",
            "  → ROI: [370, 620, 1260, 300], Sim=0.9143\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9143\n",
            "  → ROI: [370, 620, 1280, 300], Sim=0.9171\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9171\n",
            "  → ROI: [370, 620, 1300, 300], Sim=0.9199\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9199\n",
            "  → ROI: [370, 620, 1320, 300], Sim=0.9203\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9203\n",
            "  → ROI: [370, 620, 1340, 300], Sim=0.9254\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9254\n",
            "  → ROI: [370, 620, 1360, 300], Sim=0.9364\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9364\n",
            "  → ROI: [370, 620, 1380, 300], Sim=0.9367\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9367\n",
            "  → ROI: [370, 620, 1400, 300], Sim=0.9343\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1420, 300], Sim=0.9550\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9550\n",
            "  → ROI: [370, 620, 1440, 300], Sim=0.9576\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9576\n",
            "  → ROI: [370, 620, 1460, 300], Sim=0.9604\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9604\n",
            "  → ROI: [370, 620, 1480, 300], Sim=0.9679\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9679\n",
            "  → ROI: [370, 620, 1500, 300], Sim=0.9706\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9706\n",
            "  → ROI: [370, 620, 1520, 300], Sim=0.8585\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1540, 300], Sim=0.9781\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9781\n",
            "  → ROI: [370, 620, 1560, 300], Sim=0.9854\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9854\n",
            "  → ROI: [370, 620, 1580, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "    ✔ New best: 0.9903\n",
            "  → ROI: [370, 620, 1600, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1620, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1640, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1660, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1680, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1700, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1720, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1740, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1760, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1780, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1800, 300], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "— Stopping right: 11 unchanged-sim steps\n",
            "\n",
            "=== Expanding UP ===\n",
            "  → ROI: [370, 600, 1580, 320], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 580, 1580, 340], Sim=0.9062\n",
            "    Text snippet: uaeveiopmei ui CivIV Classiiien). It changed the idea of fin…\n",
            "  → ROI: [370, 560, 1580, 360], Sim=0.9193\n",
            "    Text snippet: development of CNN classifiers. It changed the idea of findi…\n",
            "  → ROI: [370, 540, 1580, 380], Sim=0.9238\n",
            "    Text snippet: development of CNN classifiers. It changed the idea of findi…\n",
            "  → ROI: [370, 520, 1580, 400], Sim=0.8257\n",
            "    Text snippet: ME Mncepliun ielwui Was ai mpOn talit Meslune M lnie develop…\n",
            "  → ROI: [370, 500, 1580, 420], Sim=0.8127\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 480, 1580, 440], Sim=0.8167\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 460, 1580, 460], Sim=0.8224\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 440, 1580, 480], Sim=0.8207\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 420, 1580, 500], Sim=0.8127\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 400, 1580, 520], Sim=0.8127\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 380, 1580, 540], Sim=0.8207\n",
            "    Text snippet: The Inception network was an important milestone in the deve…\n",
            "  → ROI: [370, 360, 1580, 560], Sim=0.7701\n",
            "    Text snippet: Tccpliun | VClVvui ^ IvOivaliui| The Inception network was a…\n",
            "  → ROI: [370, 340, 1580, 580], Sim=0.7698\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 320, 1580, 600], Sim=0.7736\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 300, 1580, 620], Sim=0.7774\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 280, 1580, 640], Sim=0.7774\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 260, 1580, 660], Sim=0.7698\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 240, 1580, 680], Sim=0.7698\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 220, 1580, 700], Sim=0.7774\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 200, 1580, 720], Sim=0.7774\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "  → ROI: [370, 180, 1580, 740], Sim=0.7698\n",
            "    Text snippet: nception Network Motivation The Inception network was an imp…\n",
            "— Stopping up: 21 low-sim steps\n",
            "\n",
            "=== Expanding DOWN ===\n",
            "  → ROI: [370, 620, 1580, 320], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 340], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 360], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 380], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 400], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 420], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 440], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 460], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 480], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 500], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 520], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 540], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 560], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 580], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 600], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 620], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 640], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 660], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 680], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 700], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 720], Sim=0.9855\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 740], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 760], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 780], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 800], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 820], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 840], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 620, 1580, 860], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 600, 1580, 880], Sim=0.9903\n",
            "    Text snippet: It changed the idea of finding optimized filters, filter siz…\n",
            "  → ROI: [370, 580, 1580, 900], Sim=0.9107\n",
            "    Text snippet: uaeveiopmei ui CivIV Classiiien). It changed the idea of fin…\n",
            "— Stopping down: 21 low-sim steps\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final ROI on padded image: [370, 620, 1580, 300]\n",
            "Final ROI on original image: [170, 420, 1580, 300]\n",
            "Cropped region saved as: refined_crop.png\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}